{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = wandb.Api()\n",
    "\n",
    "projects = [run.removesuffix(\".csv\") for run in os.listdir() if run.endswith(\".csv\") and run != \"runs.csv\"]\n",
    "allowed_runs = [\n",
    "    \"fancy-vortex-1 - (bloomz-560m_System_Prompt_dataset)\",\n",
    "    \"generous-wood-3 - (flan-t5-base_Translation_dataset)\",\n",
    "    \"winter-bird-1 - (gpt2-large_Instruct_dataset)\",\n",
    "    \"avid-cosmos-4 - (gpt2-large_System_Prompt_dataset)\",\n",
    "    \"astral-jazz-1 - (gpt2_Instruct_dataset)\",\n",
    "    \"graceful-lake-6 - (gpt2_System_Prompt_dataset)\",\n",
    "    \"nagus-dukat-12 - (gpt2_Text_generation_dataset)\",\n",
    "    \"quiet-lion-1 - (MicroLlama_Instruct_dataset)\",\n",
    "    \"lively-deluge-2 - (MicroLlama_Text_generation_dataset)\",\n",
    "    \"jolly-waterfall-1 - (MicroLlama_Text_generation_dataset)\",\n",
    "    \"dauntless-pine-2 - (MicroLlama_Translation_dataset)\",\n",
    "    \"floral-wave-1 - (t5-base-finetuned-wikiSQL_Translation_dataset)\",\n",
    "    \"divine-tree-1 - (TinyLLama-v0_Chatbot_dataset)\",\n",
    "    \"lunar-lake-1 - (TinyLLama-v0_Chatbot_instruct_dataset)\",\n",
    "    \"nagus-phage-1 - (TinyLLama-v0_Instruct_dataset)\",\n",
    "    \"warm-rain-3 - (TinyLLama-v0_System_Prompt_dataset)\",\n",
    "    \"rosy-cherry-2 - (TinyLLama-v0_System_Prompt_dataset)\",\n",
    "    \"swift-music-1 - (TinyLLama-v0_System_Prompt_dataset)\",\n",
    "    \"trill-quark-1 - (TinyLLama-v0_Text_completition_dataset)\",\n",
    "    \"radiant-star-2 - (TinyLLama-v0_Text_generation_dataset)\",\n",
    "    \"daily-glitter-1 - (TinyLLama-v0_Text_generation_dataset)\",\n",
    "    \"desert-forest-1 - (TinyLLama-v0_Translation_dataset)\",\n",
    "]\n",
    "summary = []\n",
    "for p in projects:\n",
    "    runs = api.runs(f\"littlebig-team/{p}\")\n",
    "    for run in runs:\n",
    "        d = run.summary._json_dict\n",
    "        name = f\"{run.name} - ({p})\"\n",
    "        if name in allowed_runs:\n",
    "            d[\"name\"] = name\n",
    "            summary.append(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df = pd.DataFrame(summary)\n",
    "runs_df.dropna(subset=[\"eval/loss\"], inplace=True)\n",
    "#runs_df.to_csv(\"runs.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS_FACTOR = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_df[\"_step\"] = runs_df[\"_step\"] * STEPS_FACTOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_step</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>train/epoch</th>\n",
       "      <th>train/global_step</th>\n",
       "      <th>eval/samples_per_second</th>\n",
       "      <th>_runtime</th>\n",
       "      <th>eval/loss</th>\n",
       "      <th>train/loss</th>\n",
       "      <th>eval/runtime</th>\n",
       "      <th>train/grad_norm</th>\n",
       "      <th>train/learning_rate</th>\n",
       "      <th>eval/steps_per_second</th>\n",
       "      <th>name</th>\n",
       "      <th>_wandb</th>\n",
       "      <th>train/train_loss</th>\n",
       "      <th>train/train_steps_per_second</th>\n",
       "      <th>train/train_samples_per_second</th>\n",
       "      <th>train/train_runtime</th>\n",
       "      <th>train/total_flos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28500</td>\n",
       "      <td>1.712087e+09</td>\n",
       "      <td>4.62</td>\n",
       "      <td>8250</td>\n",
       "      <td>67.239</td>\n",
       "      <td>9464.082738</td>\n",
       "      <td>4.749443e-01</td>\n",
       "      <td>0.4213</td>\n",
       "      <td>14.8722</td>\n",
       "      <td>3.934069</td>\n",
       "      <td>1.080839e-04</td>\n",
       "      <td>8.405</td>\n",
       "      <td>fancy-vortex-1 - (bloomz-560m_System_Prompt_da...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19250</td>\n",
       "      <td>1.712664e+09</td>\n",
       "      <td>0.36</td>\n",
       "      <td>7350</td>\n",
       "      <td>8.253</td>\n",
       "      <td>70909.952975</td>\n",
       "      <td>1.577744e-05</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>121.1662</td>\n",
       "      <td>0.036515</td>\n",
       "      <td>1.927084e-04</td>\n",
       "      <td>1.032</td>\n",
       "      <td>generous-wood-3 - (flan-t5-base_Translation_da...</td>\n",
       "      <td>{'runtime': 72091}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4000</td>\n",
       "      <td>1.712866e+09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1250</td>\n",
       "      <td>9.581</td>\n",
       "      <td>10377.998928</td>\n",
       "      <td>5.127320e-01</td>\n",
       "      <td>0.6123</td>\n",
       "      <td>104.3732</td>\n",
       "      <td>0.359797</td>\n",
       "      <td>1.979895e-04</td>\n",
       "      <td>1.198</td>\n",
       "      <td>winter-bird-1 - (gpt2-large_Instruct_dataset)</td>\n",
       "      <td>{'runtime': 10417}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4250</td>\n",
       "      <td>1.711464e+09</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1300</td>\n",
       "      <td>48.204</td>\n",
       "      <td>1018.836271</td>\n",
       "      <td>5.823997e-01</td>\n",
       "      <td>0.6105</td>\n",
       "      <td>20.7454</td>\n",
       "      <td>0.361119</td>\n",
       "      <td>1.854509e-04</td>\n",
       "      <td>6.025</td>\n",
       "      <td>avid-cosmos-4 - (gpt2-large_System_Prompt_data...</td>\n",
       "      <td>{'runtime': 1055}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31500</td>\n",
       "      <td>1.712606e+09</td>\n",
       "      <td>0.38</td>\n",
       "      <td>9100</td>\n",
       "      <td>31.772</td>\n",
       "      <td>20252.913726</td>\n",
       "      <td>3.298344e+00</td>\n",
       "      <td>3.6490</td>\n",
       "      <td>31.4742</td>\n",
       "      <td>4.633813</td>\n",
       "      <td>1.847314e-04</td>\n",
       "      <td>3.972</td>\n",
       "      <td>astral-jazz-1 - (gpt2_Instruct_dataset)</td>\n",
       "      <td>{'runtime': 20410}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>31000</td>\n",
       "      <td>1.711313e+09</td>\n",
       "      <td>5.00</td>\n",
       "      <td>8920</td>\n",
       "      <td>244.586</td>\n",
       "      <td>4678.924252</td>\n",
       "      <td>4.631605e-01</td>\n",
       "      <td>0.4852</td>\n",
       "      <td>4.0885</td>\n",
       "      <td>0.312119</td>\n",
       "      <td>4.485311e-06</td>\n",
       "      <td>30.573</td>\n",
       "      <td>graceful-lake-6 - (gpt2_System_Prompt_dataset)</td>\n",
       "      <td>{'runtime': 4678}</td>\n",
       "      <td>0.587013</td>\n",
       "      <td>1.908</td>\n",
       "      <td>61.087</td>\n",
       "      <td>4674.8995</td>\n",
       "      <td>2.795771e+16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32500</td>\n",
       "      <td>1.712411e+09</td>\n",
       "      <td>0.47</td>\n",
       "      <td>9400</td>\n",
       "      <td>33.479</td>\n",
       "      <td>16030.273072</td>\n",
       "      <td>3.247270e+00</td>\n",
       "      <td>3.5779</td>\n",
       "      <td>29.8692</td>\n",
       "      <td>1.930838</td>\n",
       "      <td>1.813482e-04</td>\n",
       "      <td>4.185</td>\n",
       "      <td>nagus-dukat-12 - (gpt2_Text_generation_dataset)</td>\n",
       "      <td>{'runtime': 16097}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14500</td>\n",
       "      <td>1.712686e+09</td>\n",
       "      <td>0.18</td>\n",
       "      <td>4250</td>\n",
       "      <td>17.339</td>\n",
       "      <td>17938.424347</td>\n",
       "      <td>1.551786e+00</td>\n",
       "      <td>1.6189</td>\n",
       "      <td>57.6732</td>\n",
       "      <td>2.191106</td>\n",
       "      <td>1.964774e-04</td>\n",
       "      <td>2.167</td>\n",
       "      <td>quiet-lion-1 - (MicroLlama_Instruct_dataset)</td>\n",
       "      <td>{'runtime': 18054}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6750</td>\n",
       "      <td>1.712173e+09</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2000</td>\n",
       "      <td>43.038</td>\n",
       "      <td>2780.628785</td>\n",
       "      <td>1.702201e+00</td>\n",
       "      <td>1.7813</td>\n",
       "      <td>23.2354</td>\n",
       "      <td>2.405196</td>\n",
       "      <td>1.980173e-03</td>\n",
       "      <td>5.380</td>\n",
       "      <td>lively-deluge-2 - (MicroLlama_Text_generation_...</td>\n",
       "      <td>{'runtime': 2782}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7250</td>\n",
       "      <td>1.712173e+09</td>\n",
       "      <td>0.11</td>\n",
       "      <td>2200</td>\n",
       "      <td>23.037</td>\n",
       "      <td>2863.626665</td>\n",
       "      <td>1.759959e+00</td>\n",
       "      <td>1.8016</td>\n",
       "      <td>43.4092</td>\n",
       "      <td>0.388681</td>\n",
       "      <td>1.978189e-04</td>\n",
       "      <td>2.880</td>\n",
       "      <td>jolly-waterfall-1 - (MicroLlama_Text_generatio...</td>\n",
       "      <td>{'runtime': 2918}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13750</td>\n",
       "      <td>1.712686e+09</td>\n",
       "      <td>0.20</td>\n",
       "      <td>4000</td>\n",
       "      <td>17.198</td>\n",
       "      <td>18041.268478</td>\n",
       "      <td>1.582371e+00</td>\n",
       "      <td>1.6390</td>\n",
       "      <td>58.1470</td>\n",
       "      <td>0.824418</td>\n",
       "      <td>1.960327e-04</td>\n",
       "      <td>2.150</td>\n",
       "      <td>dauntless-pine-2 - (MicroLlama_Translation_dat...</td>\n",
       "      <td>{'runtime': 18129}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>156500</td>\n",
       "      <td>1.713194e+09</td>\n",
       "      <td>2.92</td>\n",
       "      <td>58800</td>\n",
       "      <td>9.454</td>\n",
       "      <td>523698.825889</td>\n",
       "      <td>5.901650e-07</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>105.7746</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>1.416536e-04</td>\n",
       "      <td>1.182</td>\n",
       "      <td>floral-wave-1 - (t5-base-finetuned-wikiSQL_Tra...</td>\n",
       "      <td>{'runtime': 524246}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>24750</td>\n",
       "      <td>1.712606e+09</td>\n",
       "      <td>0.34</td>\n",
       "      <td>7200</td>\n",
       "      <td>139.528</td>\n",
       "      <td>7713.439185</td>\n",
       "      <td>4.354541e+00</td>\n",
       "      <td>4.4350</td>\n",
       "      <td>7.1670</td>\n",
       "      <td>1.211561</td>\n",
       "      <td>1.863962e-04</td>\n",
       "      <td>17.441</td>\n",
       "      <td>divine-tree-1 - (TinyLLama-v0_Chatbot_dataset)</td>\n",
       "      <td>{'runtime': 7715}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>38250</td>\n",
       "      <td>1.712598e+09</td>\n",
       "      <td>0.55</td>\n",
       "      <td>11000</td>\n",
       "      <td>131.781</td>\n",
       "      <td>12061.697638</td>\n",
       "      <td>4.165835e+00</td>\n",
       "      <td>4.3116</td>\n",
       "      <td>7.5884</td>\n",
       "      <td>1.347117</td>\n",
       "      <td>1.781727e-04</td>\n",
       "      <td>16.473</td>\n",
       "      <td>lunar-lake-1 - (TinyLLama-v0_Chatbot_instruct_...</td>\n",
       "      <td>{'runtime': 12064}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>17250</td>\n",
       "      <td>1.712416e+09</td>\n",
       "      <td>0.21</td>\n",
       "      <td>5000</td>\n",
       "      <td>173.619</td>\n",
       "      <td>4230.931648</td>\n",
       "      <td>4.472071e+00</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>5.7597</td>\n",
       "      <td>1.032368</td>\n",
       "      <td>1.916122e-04</td>\n",
       "      <td>21.702</td>\n",
       "      <td>nagus-phage-1 - (TinyLLama-v0_Instruct_dataset)</td>\n",
       "      <td>{'runtime': 4234}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>31000</td>\n",
       "      <td>1.711477e+09</td>\n",
       "      <td>9.99</td>\n",
       "      <td>8920</td>\n",
       "      <td>360.276</td>\n",
       "      <td>4247.262381</td>\n",
       "      <td>4.706320e+00</td>\n",
       "      <td>4.7033</td>\n",
       "      <td>2.7756</td>\n",
       "      <td>0.957120</td>\n",
       "      <td>4.485311e-07</td>\n",
       "      <td>45.035</td>\n",
       "      <td>warm-rain-3 - (TinyLLama-v0_System_Prompt_data...</td>\n",
       "      <td>{'runtime': 4246}</td>\n",
       "      <td>4.861362</td>\n",
       "      <td>2.102</td>\n",
       "      <td>134.606</td>\n",
       "      <td>4243.1255</td>\n",
       "      <td>2.065276e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>62250</td>\n",
       "      <td>1.711481e+09</td>\n",
       "      <td>10.00</td>\n",
       "      <td>17840</td>\n",
       "      <td>386.890</td>\n",
       "      <td>9485.160096</td>\n",
       "      <td>4.960893e+00</td>\n",
       "      <td>4.9599</td>\n",
       "      <td>2.5847</td>\n",
       "      <td>0.593591</td>\n",
       "      <td>4.484808e-08</td>\n",
       "      <td>48.361</td>\n",
       "      <td>rosy-cherry-2 - (TinyLLama-v0_System_Prompt_da...</td>\n",
       "      <td>{'runtime': 9484}</td>\n",
       "      <td>5.272981</td>\n",
       "      <td>1.882</td>\n",
       "      <td>60.243</td>\n",
       "      <td>9480.7818</td>\n",
       "      <td>1.904129e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>62250</td>\n",
       "      <td>1.711474e+09</td>\n",
       "      <td>10.00</td>\n",
       "      <td>17840</td>\n",
       "      <td>311.110</td>\n",
       "      <td>9516.987525</td>\n",
       "      <td>4.612257e+00</td>\n",
       "      <td>4.6444</td>\n",
       "      <td>3.2143</td>\n",
       "      <td>1.516271</td>\n",
       "      <td>4.484808e-07</td>\n",
       "      <td>38.889</td>\n",
       "      <td>swift-music-1 - (TinyLLama-v0_System_Prompt_da...</td>\n",
       "      <td>{'runtime': 9516}</td>\n",
       "      <td>4.741254</td>\n",
       "      <td>1.875</td>\n",
       "      <td>60.039</td>\n",
       "      <td>9513.0129</td>\n",
       "      <td>1.902888e+15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>28000</td>\n",
       "      <td>1.712416e+09</td>\n",
       "      <td>0.37</td>\n",
       "      <td>8100</td>\n",
       "      <td>182.086</td>\n",
       "      <td>7486.910716</td>\n",
       "      <td>4.345140e+00</td>\n",
       "      <td>4.4599</td>\n",
       "      <td>5.4919</td>\n",
       "      <td>1.530812</td>\n",
       "      <td>1.853068e-04</td>\n",
       "      <td>22.761</td>\n",
       "      <td>trill-quark-1 - (TinyLLama-v0_Text_completitio...</td>\n",
       "      <td>{'runtime': 7543}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>56000</td>\n",
       "      <td>1.711668e+09</td>\n",
       "      <td>0.80</td>\n",
       "      <td>16100</td>\n",
       "      <td>167.834</td>\n",
       "      <td>10977.472251</td>\n",
       "      <td>4.066646e+00</td>\n",
       "      <td>4.2258</td>\n",
       "      <td>5.9583</td>\n",
       "      <td>1.284530</td>\n",
       "      <td>1.840256e-04</td>\n",
       "      <td>20.979</td>\n",
       "      <td>radiant-star-2 - (TinyLLama-v0_Text_generation...</td>\n",
       "      <td>{'runtime': 11024}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>56750</td>\n",
       "      <td>1.711669e+09</td>\n",
       "      <td>0.81</td>\n",
       "      <td>16300</td>\n",
       "      <td>176.321</td>\n",
       "      <td>11161.495278</td>\n",
       "      <td>4.020950e+00</td>\n",
       "      <td>4.1489</td>\n",
       "      <td>5.6715</td>\n",
       "      <td>1.509033</td>\n",
       "      <td>1.838272e-04</td>\n",
       "      <td>22.040</td>\n",
       "      <td>daily-glitter-1 - (TinyLLama-v0_Text_generatio...</td>\n",
       "      <td>{'runtime': 11199}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>36500</td>\n",
       "      <td>1.712686e+09</td>\n",
       "      <td>0.52</td>\n",
       "      <td>10500</td>\n",
       "      <td>93.193</td>\n",
       "      <td>18126.197500</td>\n",
       "      <td>4.237285e+00</td>\n",
       "      <td>4.2765</td>\n",
       "      <td>10.7304</td>\n",
       "      <td>1.086964</td>\n",
       "      <td>1.791651e-04</td>\n",
       "      <td>11.649</td>\n",
       "      <td>desert-forest-1 - (TinyLLama-v0_Translation_da...</td>\n",
       "      <td>{'runtime': 18249}</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     _step    _timestamp  train/epoch  train/global_step  \\\n",
       "0    28500  1.712087e+09         4.62               8250   \n",
       "1    19250  1.712664e+09         0.36               7350   \n",
       "2     4000  1.712866e+09         0.05               1250   \n",
       "3     4250  1.711464e+09         0.36               1300   \n",
       "4    31500  1.712606e+09         0.38               9100   \n",
       "5    31000  1.711313e+09         5.00               8920   \n",
       "6    32500  1.712411e+09         0.47               9400   \n",
       "7    14500  1.712686e+09         0.18               4250   \n",
       "8     6750  1.712173e+09         0.10               2000   \n",
       "9     7250  1.712173e+09         0.11               2200   \n",
       "10   13750  1.712686e+09         0.20               4000   \n",
       "11  156500  1.713194e+09         2.92              58800   \n",
       "12   24750  1.712606e+09         0.34               7200   \n",
       "13   38250  1.712598e+09         0.55              11000   \n",
       "14   17250  1.712416e+09         0.21               5000   \n",
       "15   31000  1.711477e+09         9.99               8920   \n",
       "16   62250  1.711481e+09        10.00              17840   \n",
       "17   62250  1.711474e+09        10.00              17840   \n",
       "18   28000  1.712416e+09         0.37               8100   \n",
       "19   56000  1.711668e+09         0.80              16100   \n",
       "20   56750  1.711669e+09         0.81              16300   \n",
       "21   36500  1.712686e+09         0.52              10500   \n",
       "\n",
       "    eval/samples_per_second       _runtime     eval/loss  train/loss  \\\n",
       "0                    67.239    9464.082738  4.749443e-01      0.4213   \n",
       "1                     8.253   70909.952975  1.577744e-05      0.0017   \n",
       "2                     9.581   10377.998928  5.127320e-01      0.6123   \n",
       "3                    48.204    1018.836271  5.823997e-01      0.6105   \n",
       "4                    31.772   20252.913726  3.298344e+00      3.6490   \n",
       "5                   244.586    4678.924252  4.631605e-01      0.4852   \n",
       "6                    33.479   16030.273072  3.247270e+00      3.5779   \n",
       "7                    17.339   17938.424347  1.551786e+00      1.6189   \n",
       "8                    43.038    2780.628785  1.702201e+00      1.7813   \n",
       "9                    23.037    2863.626665  1.759959e+00      1.8016   \n",
       "10                   17.198   18041.268478  1.582371e+00      1.6390   \n",
       "11                    9.454  523698.825889  5.901650e-07      0.0002   \n",
       "12                  139.528    7713.439185  4.354541e+00      4.4350   \n",
       "13                  131.781   12061.697638  4.165835e+00      4.3116   \n",
       "14                  173.619    4230.931648  4.472071e+00      4.5718   \n",
       "15                  360.276    4247.262381  4.706320e+00      4.7033   \n",
       "16                  386.890    9485.160096  4.960893e+00      4.9599   \n",
       "17                  311.110    9516.987525  4.612257e+00      4.6444   \n",
       "18                  182.086    7486.910716  4.345140e+00      4.4599   \n",
       "19                  167.834   10977.472251  4.066646e+00      4.2258   \n",
       "20                  176.321   11161.495278  4.020950e+00      4.1489   \n",
       "21                   93.193   18126.197500  4.237285e+00      4.2765   \n",
       "\n",
       "    eval/runtime  train/grad_norm  train/learning_rate  eval/steps_per_second  \\\n",
       "0        14.8722         3.934069         1.080839e-04                  8.405   \n",
       "1       121.1662         0.036515         1.927084e-04                  1.032   \n",
       "2       104.3732         0.359797         1.979895e-04                  1.198   \n",
       "3        20.7454         0.361119         1.854509e-04                  6.025   \n",
       "4        31.4742         4.633813         1.847314e-04                  3.972   \n",
       "5         4.0885         0.312119         4.485311e-06                 30.573   \n",
       "6        29.8692         1.930838         1.813482e-04                  4.185   \n",
       "7        57.6732         2.191106         1.964774e-04                  2.167   \n",
       "8        23.2354         2.405196         1.980173e-03                  5.380   \n",
       "9        43.4092         0.388681         1.978189e-04                  2.880   \n",
       "10       58.1470         0.824418         1.960327e-04                  2.150   \n",
       "11      105.7746         0.000743         1.416536e-04                  1.182   \n",
       "12        7.1670         1.211561         1.863962e-04                 17.441   \n",
       "13        7.5884         1.347117         1.781727e-04                 16.473   \n",
       "14        5.7597         1.032368         1.916122e-04                 21.702   \n",
       "15        2.7756         0.957120         4.485311e-07                 45.035   \n",
       "16        2.5847         0.593591         4.484808e-08                 48.361   \n",
       "17        3.2143         1.516271         4.484808e-07                 38.889   \n",
       "18        5.4919         1.530812         1.853068e-04                 22.761   \n",
       "19        5.9583         1.284530         1.840256e-04                 20.979   \n",
       "20        5.6715         1.509033         1.838272e-04                 22.040   \n",
       "21       10.7304         1.086964         1.791651e-04                 11.649   \n",
       "\n",
       "                                                 name               _wandb  \\\n",
       "0   fancy-vortex-1 - (bloomz-560m_System_Prompt_da...                  NaN   \n",
       "1   generous-wood-3 - (flan-t5-base_Translation_da...   {'runtime': 72091}   \n",
       "2       winter-bird-1 - (gpt2-large_Instruct_dataset)   {'runtime': 10417}   \n",
       "3   avid-cosmos-4 - (gpt2-large_System_Prompt_data...    {'runtime': 1055}   \n",
       "4             astral-jazz-1 - (gpt2_Instruct_dataset)   {'runtime': 20410}   \n",
       "5      graceful-lake-6 - (gpt2_System_Prompt_dataset)    {'runtime': 4678}   \n",
       "6     nagus-dukat-12 - (gpt2_Text_generation_dataset)   {'runtime': 16097}   \n",
       "7        quiet-lion-1 - (MicroLlama_Instruct_dataset)   {'runtime': 18054}   \n",
       "8   lively-deluge-2 - (MicroLlama_Text_generation_...    {'runtime': 2782}   \n",
       "9   jolly-waterfall-1 - (MicroLlama_Text_generatio...    {'runtime': 2918}   \n",
       "10  dauntless-pine-2 - (MicroLlama_Translation_dat...   {'runtime': 18129}   \n",
       "11  floral-wave-1 - (t5-base-finetuned-wikiSQL_Tra...  {'runtime': 524246}   \n",
       "12     divine-tree-1 - (TinyLLama-v0_Chatbot_dataset)    {'runtime': 7715}   \n",
       "13  lunar-lake-1 - (TinyLLama-v0_Chatbot_instruct_...   {'runtime': 12064}   \n",
       "14    nagus-phage-1 - (TinyLLama-v0_Instruct_dataset)    {'runtime': 4234}   \n",
       "15  warm-rain-3 - (TinyLLama-v0_System_Prompt_data...    {'runtime': 4246}   \n",
       "16  rosy-cherry-2 - (TinyLLama-v0_System_Prompt_da...    {'runtime': 9484}   \n",
       "17  swift-music-1 - (TinyLLama-v0_System_Prompt_da...    {'runtime': 9516}   \n",
       "18  trill-quark-1 - (TinyLLama-v0_Text_completitio...    {'runtime': 7543}   \n",
       "19  radiant-star-2 - (TinyLLama-v0_Text_generation...   {'runtime': 11024}   \n",
       "20  daily-glitter-1 - (TinyLLama-v0_Text_generatio...   {'runtime': 11199}   \n",
       "21  desert-forest-1 - (TinyLLama-v0_Translation_da...   {'runtime': 18249}   \n",
       "\n",
       "    train/train_loss  train/train_steps_per_second  \\\n",
       "0                NaN                           NaN   \n",
       "1                NaN                           NaN   \n",
       "2                NaN                           NaN   \n",
       "3                NaN                           NaN   \n",
       "4                NaN                           NaN   \n",
       "5           0.587013                         1.908   \n",
       "6                NaN                           NaN   \n",
       "7                NaN                           NaN   \n",
       "8                NaN                           NaN   \n",
       "9                NaN                           NaN   \n",
       "10               NaN                           NaN   \n",
       "11               NaN                           NaN   \n",
       "12               NaN                           NaN   \n",
       "13               NaN                           NaN   \n",
       "14               NaN                           NaN   \n",
       "15          4.861362                         2.102   \n",
       "16          5.272981                         1.882   \n",
       "17          4.741254                         1.875   \n",
       "18               NaN                           NaN   \n",
       "19               NaN                           NaN   \n",
       "20               NaN                           NaN   \n",
       "21               NaN                           NaN   \n",
       "\n",
       "    train/train_samples_per_second  train/train_runtime  train/total_flos  \n",
       "0                              NaN                  NaN               NaN  \n",
       "1                              NaN                  NaN               NaN  \n",
       "2                              NaN                  NaN               NaN  \n",
       "3                              NaN                  NaN               NaN  \n",
       "4                              NaN                  NaN               NaN  \n",
       "5                           61.087            4674.8995      2.795771e+16  \n",
       "6                              NaN                  NaN               NaN  \n",
       "7                              NaN                  NaN               NaN  \n",
       "8                              NaN                  NaN               NaN  \n",
       "9                              NaN                  NaN               NaN  \n",
       "10                             NaN                  NaN               NaN  \n",
       "11                             NaN                  NaN               NaN  \n",
       "12                             NaN                  NaN               NaN  \n",
       "13                             NaN                  NaN               NaN  \n",
       "14                             NaN                  NaN               NaN  \n",
       "15                         134.606            4243.1255      2.065276e+15  \n",
       "16                          60.243            9480.7818      1.904129e+15  \n",
       "17                          60.039            9513.0129      1.902888e+15  \n",
       "18                             NaN                  NaN               NaN  \n",
       "19                             NaN                  NaN               NaN  \n",
       "20                             NaN                  NaN               NaN  \n",
       "21                             NaN                  NaN               NaN  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seconds_to_hms(seconds):\n",
    "    hours = int(seconds // 3600)\n",
    "    minutes = int((seconds % 3600) // 60)\n",
    "    seconds = int(seconds % 60)\n",
    "    return f\"{hours}h {minutes}m {seconds}s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergi\\AppData\\Local\\Temp\\ipykernel_35092\\2643292856.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  summary_df[\"runtime_hms\"] = runs_df[\"_runtime\"].apply(seconds_to_hms)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>eval/loss</th>\n",
       "      <th>train/learning_rate</th>\n",
       "      <th>_step</th>\n",
       "      <th>runtime_hms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fancy-vortex-1 - (bloomz-560m_System_Prompt_da...</td>\n",
       "      <td>4.749443e-01</td>\n",
       "      <td>1.080839e-04</td>\n",
       "      <td>28500</td>\n",
       "      <td>2h 37m 44s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>generous-wood-3 - (flan-t5-base_Translation_da...</td>\n",
       "      <td>1.577744e-05</td>\n",
       "      <td>1.927084e-04</td>\n",
       "      <td>19250</td>\n",
       "      <td>19h 41m 49s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>winter-bird-1 - (gpt2-large_Instruct_dataset)</td>\n",
       "      <td>5.127320e-01</td>\n",
       "      <td>1.979895e-04</td>\n",
       "      <td>4000</td>\n",
       "      <td>2h 52m 57s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avid-cosmos-4 - (gpt2-large_System_Prompt_data...</td>\n",
       "      <td>5.823997e-01</td>\n",
       "      <td>1.854509e-04</td>\n",
       "      <td>4250</td>\n",
       "      <td>0h 16m 58s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>astral-jazz-1 - (gpt2_Instruct_dataset)</td>\n",
       "      <td>3.298344e+00</td>\n",
       "      <td>1.847314e-04</td>\n",
       "      <td>31500</td>\n",
       "      <td>5h 37m 32s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>graceful-lake-6 - (gpt2_System_Prompt_dataset)</td>\n",
       "      <td>4.631605e-01</td>\n",
       "      <td>4.485311e-06</td>\n",
       "      <td>31000</td>\n",
       "      <td>1h 17m 58s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>nagus-dukat-12 - (gpt2_Text_generation_dataset)</td>\n",
       "      <td>3.247270e+00</td>\n",
       "      <td>1.813482e-04</td>\n",
       "      <td>32500</td>\n",
       "      <td>4h 27m 10s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>quiet-lion-1 - (MicroLlama_Instruct_dataset)</td>\n",
       "      <td>1.551786e+00</td>\n",
       "      <td>1.964774e-04</td>\n",
       "      <td>14500</td>\n",
       "      <td>4h 58m 58s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lively-deluge-2 - (MicroLlama_Text_generation_...</td>\n",
       "      <td>1.702201e+00</td>\n",
       "      <td>1.980173e-03</td>\n",
       "      <td>6750</td>\n",
       "      <td>0h 46m 20s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>jolly-waterfall-1 - (MicroLlama_Text_generatio...</td>\n",
       "      <td>1.759959e+00</td>\n",
       "      <td>1.978189e-04</td>\n",
       "      <td>7250</td>\n",
       "      <td>0h 47m 43s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dauntless-pine-2 - (MicroLlama_Translation_dat...</td>\n",
       "      <td>1.582371e+00</td>\n",
       "      <td>1.960327e-04</td>\n",
       "      <td>13750</td>\n",
       "      <td>5h 0m 41s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>floral-wave-1 - (t5-base-finetuned-wikiSQL_Tra...</td>\n",
       "      <td>5.901650e-07</td>\n",
       "      <td>1.416536e-04</td>\n",
       "      <td>156500</td>\n",
       "      <td>145h 28m 18s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>divine-tree-1 - (TinyLLama-v0_Chatbot_dataset)</td>\n",
       "      <td>4.354541e+00</td>\n",
       "      <td>1.863962e-04</td>\n",
       "      <td>24750</td>\n",
       "      <td>2h 8m 33s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>lunar-lake-1 - (TinyLLama-v0_Chatbot_instruct_...</td>\n",
       "      <td>4.165835e+00</td>\n",
       "      <td>1.781727e-04</td>\n",
       "      <td>38250</td>\n",
       "      <td>3h 21m 1s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>nagus-phage-1 - (TinyLLama-v0_Instruct_dataset)</td>\n",
       "      <td>4.472071e+00</td>\n",
       "      <td>1.916122e-04</td>\n",
       "      <td>17250</td>\n",
       "      <td>1h 10m 30s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>warm-rain-3 - (TinyLLama-v0_System_Prompt_data...</td>\n",
       "      <td>4.706320e+00</td>\n",
       "      <td>4.485311e-07</td>\n",
       "      <td>31000</td>\n",
       "      <td>1h 10m 47s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rosy-cherry-2 - (TinyLLama-v0_System_Prompt_da...</td>\n",
       "      <td>4.960893e+00</td>\n",
       "      <td>4.484808e-08</td>\n",
       "      <td>62250</td>\n",
       "      <td>2h 38m 5s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>swift-music-1 - (TinyLLama-v0_System_Prompt_da...</td>\n",
       "      <td>4.612257e+00</td>\n",
       "      <td>4.484808e-07</td>\n",
       "      <td>62250</td>\n",
       "      <td>2h 38m 36s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>trill-quark-1 - (TinyLLama-v0_Text_completitio...</td>\n",
       "      <td>4.345140e+00</td>\n",
       "      <td>1.853068e-04</td>\n",
       "      <td>28000</td>\n",
       "      <td>2h 4m 46s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>radiant-star-2 - (TinyLLama-v0_Text_generation...</td>\n",
       "      <td>4.066646e+00</td>\n",
       "      <td>1.840256e-04</td>\n",
       "      <td>56000</td>\n",
       "      <td>3h 2m 57s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>daily-glitter-1 - (TinyLLama-v0_Text_generatio...</td>\n",
       "      <td>4.020950e+00</td>\n",
       "      <td>1.838272e-04</td>\n",
       "      <td>56750</td>\n",
       "      <td>3h 6m 1s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>desert-forest-1 - (TinyLLama-v0_Translation_da...</td>\n",
       "      <td>4.237285e+00</td>\n",
       "      <td>1.791651e-04</td>\n",
       "      <td>36500</td>\n",
       "      <td>5h 2m 6s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 name     eval/loss  \\\n",
       "0   fancy-vortex-1 - (bloomz-560m_System_Prompt_da...  4.749443e-01   \n",
       "1   generous-wood-3 - (flan-t5-base_Translation_da...  1.577744e-05   \n",
       "2       winter-bird-1 - (gpt2-large_Instruct_dataset)  5.127320e-01   \n",
       "3   avid-cosmos-4 - (gpt2-large_System_Prompt_data...  5.823997e-01   \n",
       "4             astral-jazz-1 - (gpt2_Instruct_dataset)  3.298344e+00   \n",
       "5      graceful-lake-6 - (gpt2_System_Prompt_dataset)  4.631605e-01   \n",
       "6     nagus-dukat-12 - (gpt2_Text_generation_dataset)  3.247270e+00   \n",
       "7        quiet-lion-1 - (MicroLlama_Instruct_dataset)  1.551786e+00   \n",
       "8   lively-deluge-2 - (MicroLlama_Text_generation_...  1.702201e+00   \n",
       "9   jolly-waterfall-1 - (MicroLlama_Text_generatio...  1.759959e+00   \n",
       "10  dauntless-pine-2 - (MicroLlama_Translation_dat...  1.582371e+00   \n",
       "11  floral-wave-1 - (t5-base-finetuned-wikiSQL_Tra...  5.901650e-07   \n",
       "12     divine-tree-1 - (TinyLLama-v0_Chatbot_dataset)  4.354541e+00   \n",
       "13  lunar-lake-1 - (TinyLLama-v0_Chatbot_instruct_...  4.165835e+00   \n",
       "14    nagus-phage-1 - (TinyLLama-v0_Instruct_dataset)  4.472071e+00   \n",
       "15  warm-rain-3 - (TinyLLama-v0_System_Prompt_data...  4.706320e+00   \n",
       "16  rosy-cherry-2 - (TinyLLama-v0_System_Prompt_da...  4.960893e+00   \n",
       "17  swift-music-1 - (TinyLLama-v0_System_Prompt_da...  4.612257e+00   \n",
       "18  trill-quark-1 - (TinyLLama-v0_Text_completitio...  4.345140e+00   \n",
       "19  radiant-star-2 - (TinyLLama-v0_Text_generation...  4.066646e+00   \n",
       "20  daily-glitter-1 - (TinyLLama-v0_Text_generatio...  4.020950e+00   \n",
       "21  desert-forest-1 - (TinyLLama-v0_Translation_da...  4.237285e+00   \n",
       "\n",
       "    train/learning_rate   _step   runtime_hms  \n",
       "0          1.080839e-04   28500    2h 37m 44s  \n",
       "1          1.927084e-04   19250   19h 41m 49s  \n",
       "2          1.979895e-04    4000    2h 52m 57s  \n",
       "3          1.854509e-04    4250    0h 16m 58s  \n",
       "4          1.847314e-04   31500    5h 37m 32s  \n",
       "5          4.485311e-06   31000    1h 17m 58s  \n",
       "6          1.813482e-04   32500    4h 27m 10s  \n",
       "7          1.964774e-04   14500    4h 58m 58s  \n",
       "8          1.980173e-03    6750    0h 46m 20s  \n",
       "9          1.978189e-04    7250    0h 47m 43s  \n",
       "10         1.960327e-04   13750     5h 0m 41s  \n",
       "11         1.416536e-04  156500  145h 28m 18s  \n",
       "12         1.863962e-04   24750     2h 8m 33s  \n",
       "13         1.781727e-04   38250     3h 21m 1s  \n",
       "14         1.916122e-04   17250    1h 10m 30s  \n",
       "15         4.485311e-07   31000    1h 10m 47s  \n",
       "16         4.484808e-08   62250     2h 38m 5s  \n",
       "17         4.484808e-07   62250    2h 38m 36s  \n",
       "18         1.853068e-04   28000     2h 4m 46s  \n",
       "19         1.840256e-04   56000     3h 2m 57s  \n",
       "20         1.838272e-04   56750      3h 6m 1s  \n",
       "21         1.791651e-04   36500      5h 2m 6s  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_df = runs_df[[\"name\", \"eval/loss\", \"train/learning_rate\", \"_step\"]]\n",
    "summary_df[\"runtime_hms\"] = runs_df[\"_runtime\"].apply(seconds_to_hms)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(\"summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
